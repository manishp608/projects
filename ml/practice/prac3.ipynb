{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45d6b452",
   "metadata": {},
   "source": [
    "# Kmeans1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "028a783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f840542",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans:\n",
    "    def __init__(self, k=2, epochs=100, ep=1e-4, seed=42):\n",
    "        self.k = k\n",
    "        self.ep = ep\n",
    "        self.epochs = epochs\n",
    "        np.random.seed(seed)\n",
    "        self.centroids = None\n",
    "        self.labels = None\n",
    "        self.j_hist = []\n",
    "\n",
    "    def init_centroids(self, X):\n",
    "        idxs = np.random.choice(X.shape[0], self.k, replace=False)\n",
    "        return X[idxs]\n",
    "    \n",
    "    def assign_cluster(self, X, centroids):\n",
    "        assign = []\n",
    "        for x in X:\n",
    "            distances = [self._dist(x, pt) for pt in centroids]\n",
    "            assign.append(np.argmin(distances))\n",
    "        return np.array(assign)\n",
    "    \n",
    "    def _dist(self, a, b):\n",
    "        return np.sqrt(np.sum((a - b) ** 2))\n",
    "    \n",
    "    def update_centroids(self, X, labels):\n",
    "        centroids = np.zeros((self.k, X.shape[1]))\n",
    "        for i in range(self.k):\n",
    "            points = X[labels == i]\n",
    "            if len(points) > 0:\n",
    "                centroids[i] = points.mean(axis=0)\n",
    "            else:\n",
    "                centroids[i] = X[np.random.choice(X.shape[0])]\n",
    "        return centroids\n",
    "    \n",
    "    def compute_objective(self, X, labels, centroids):\n",
    "        total = 0\n",
    "        for i in range(self.k):\n",
    "            cluster_points = X[labels == i]\n",
    "            total += np.sum((cluster_points - centroids[i]) ** 2)\n",
    "\n",
    "        return total / X.shape[0]\n",
    "    \n",
    "    def fit(self, X):\n",
    "        self.centroids = self.init_centroids(X)\n",
    "        for i in range(self.epochs):\n",
    "            labels = self.assign_cluster(X, self.centroids)\n",
    "            new_centroids = self.update_centroids(X, labels)\n",
    "            j = self.compute_objective(X, labels, new_centroids)\n",
    "            self.j_hist.append(round(j, 4))\n",
    "            if np.linalg.norm(new_centroids - self.centroids) < self.ep:\n",
    "                break\n",
    "            self.centroids = new_centroids\n",
    "        self.labels = labels\n",
    "        return self\n",
    "    \n",
    "    def plot_convergence(self):\n",
    "        plt.figure()\n",
    "        plt.plot(range(1, len(self.j_hist) + 1), self.j_hist, marker='o')\n",
    "        plt.title('Convergece of KMeans Objective j')\n",
    "        plt.xlabel('epochs')\n",
    "        plt.ylabel('J (Average Squared Distance)')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_clusters(self, X):\n",
    "        plt.figure()\n",
    "        colors = ['red', 'blue', 'green', 'purple', 'orange', 'cyan']\n",
    "        for i in range(self.k):\n",
    "            pts = X[self.labels == i]\n",
    "            plt.scatter(pts[:, 0], pts[:, 1], s=50, c=colors[i % len(colors)], label=f\"Cluster {i + 1}\")\n",
    "        plt.scatter(self.centroids[:, 0], self.centroids[:, 1], c='black', s=150, marker='x', label='centroids')\n",
    "        plt.title('K Means clustering Result')\n",
    "        plt.xlabel('X')\n",
    "        plt.ylabel('Y')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b56e21",
   "metadata": {},
   "source": [
    "# DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4380e47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac03925",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DBSCAN:\n",
    "    def __init__(self, eps=3, minPts=2):\n",
    "        self.eps = eps\n",
    "        self.minPts = minPts\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.X = X\n",
    "        n = len(X)\n",
    "        self.visited = np.zeros(n, dtype=bool)\n",
    "        self.cluster_labels = np.zeros(n, dtype=int)\n",
    "        self.core_points = []\n",
    "        self.cluster_id = 0\n",
    "\n",
    "        self.dist_matrix = np.zeros((n, n))\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                self.dist_matrix[i, j] = np.linalg.norm(X[i] - X[j])\n",
    "        self.dist_matrix = np.round(self.dist_matrix, 2)\n",
    "\n",
    "        self.neighbors = []\n",
    "        for i in range(n):\n",
    "            neigh = np.where(self.dist_matrix[i] <= self.eps)[0]\n",
    "            self.neighbors.append(neigh)\n",
    "            if len(neigh) >= self.minPts:\n",
    "                self.core_points.append(i)\n",
    "\n",
    "        for i in range(n):\n",
    "            if not self.visited[i] and i in self.core_points:\n",
    "                self.cluster_id += 1\n",
    "                self.expand_cluster(i)\n",
    "\n",
    "    def expand_cluster(self, i):\n",
    "        queue = [i]\n",
    "        while queue:\n",
    "            point = queue.pop(0)\n",
    "            if not self.visited[point]:\n",
    "                self.visited[point] = True\n",
    "                self.cluster_labels[point] = self.cluster_id\n",
    "                if point in self.core_points:\n",
    "                    for neigh in self.neighbors[point]:\n",
    "                        if self.cluster_labels[neigh] == 0:\n",
    "                            queue.append(neigh)\n",
    "\n",
    "    def noise_ratio(self):\n",
    "        noise_count = np.sum(self.cluster_labels == 0)\n",
    "        return noise_count / len(self.X)\n",
    "    \n",
    "    def print_results(self):\n",
    "        print(\"Core points:\", ' '.join(str(i+1) for i in self.core_points))\n",
    "        print(\"Cluster Assignments:\", ' '.join(str(lbl) for lbl in self.cluster_labels))\n",
    "        print(\"Noise Ratio =\", round(self.noise_ratio(), 2))\n",
    "\n",
    "    def plot_clusters(self):\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        colors = ['red', 'blue', 'green', 'orange', 'purple', 'cyan']\n",
    "        for idx, label in enumerate(set(self.cluster_labels)):\n",
    "            if label == 0:\n",
    "                pts = self.X[self.cluster_labels == label]\n",
    "                plt.scatter(pts[:, 0], pts[:, 1], marker='x', color='k', label='Noise')\n",
    "            else:\n",
    "                pts = self.X[self.cluster_labels == label]\n",
    "                plt.scatter(pts[:, 0], pts[:, 1], color=colors[label % len(colors)], label=f'Cluster {label}')\n",
    "        plt.title(f'DBSCAN Clustering (eps={self.eps}, minPts={self.minPts})')\n",
    "        plt.xlabel('x1')\n",
    "        plt.ylabel('x2')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8a32f4",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "918dca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bbccee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y):\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "    ps = counts / len(y)\n",
    "    return -np.sum(ps * np.log2(ps + 1e-9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f63f82c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(y):\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "    ps = counts / len(y)\n",
    "    return 1 - np.sum(ps ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92be8401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_split(X, y, impurity_fn):\n",
    "    best_gain = -np.inf\n",
    "    best_thres = None\n",
    "    best_feature = None\n",
    "    m, n = X.shape\n",
    "\n",
    "    for f in range(n):\n",
    "        si = np.argsort(X[:, f])\n",
    "        s_X = X[si, f]\n",
    "        s_y = y[si]\n",
    "\n",
    "        thresholds = (s_X[:-1] + s_X[1:]) / 2\n",
    "        for t in thresholds:\n",
    "            left_mask = X[:, f] <= t\n",
    "            right_mask = ~left_mask\n",
    "            left_y = y[left_mask]\n",
    "            right_y = y[right_mask]\n",
    "\n",
    "            if len(left_y) == 0 or len(right_y) == 0:\n",
    "                continue\n",
    "\n",
    "            impl = impurity_fn(left_y)\n",
    "            impr = impurity_fn(right_y)\n",
    "\n",
    "            wimp = (len(left_y) / m) * impl + (len(right_y) / m) * impr\n",
    "            gain = impurity_fn(y) - wimp\n",
    "\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_thres = t\n",
    "                best_feature = f\n",
    "\n",
    "    return best_feature, best_thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7037178c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, depth=0, max_depth=None, min_samples_leaf=1, impurity_fn=entropy):\n",
    "    n_samples = len(y)\n",
    "    if depth >= max_depth or n_samples <= min_samples_leaf or len(np.unique(y)) == 1:\n",
    "        return np.bincount(y).argmax()\n",
    "    \n",
    "    f, t = best_split(X, y, impurity_fn)\n",
    "    if f is None:\n",
    "        return np.bincount(y).argmax()\n",
    "    \n",
    "    lm = X[:, f] <= t\n",
    "    rm = ~lm\n",
    "    \n",
    "    ltree = train(X[lm], y[lm], depth + 1, max_depth, min_samples_leaf, impurity_fn)\n",
    "    rtree = train(X[rm], y[rm], depth + 1, max_depth, min_samples_leaf, impurity_fn)\n",
    "\n",
    "    return {'feature': f, 'threshold': t, 'left': ltree, 'right': rtree}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc7675aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tree, sample):\n",
    "    if isinstance(tree, dict):\n",
    "        if sample[tree['feature']] <= tree['threhold']:\n",
    "            return predict(tree['left'], sample)\n",
    "        else:\n",
    "            return predict(tree['right'], sample)\n",
    "    else:\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d77a35b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(X, y, tree):\n",
    "    pred = [predict(tree, sample) for sample in X]\n",
    "    return np.mean(np.array(pred) == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2a796aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(X_train, y_train, X_val, y_val, depths, min_samples, impurity_fn):\n",
    "    best_depth = None\n",
    "    best_min_samples = None\n",
    "    best_acc = -np.inf\n",
    "    best_tree = None\n",
    "\n",
    "    for d in depths:\n",
    "        for m in min_samples:\n",
    "            tree = train(X_train, y_train, max_depth=d, min_samples_leaf=m, impurity_fn=impurity_fn)\n",
    "            val_acc = evaluate(X_val, y_val, tree)\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                best_depth = d\n",
    "                best_min_samples = m\n",
    "                best_tree = tree\n",
    "\n",
    "    return best_tree, best_depth, best_min_samples, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3f01026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_split(X, y):\n",
    "    n = len(X)\n",
    "    n_train = int(0.7 * n)\n",
    "    n_val = int(0.15 * n)\n",
    "    n_test = n - n_train - n_val\n",
    "\n",
    "    X_train = X[:n_train]\n",
    "    y_train = y[:n_train]\n",
    "\n",
    "    X_val = X[n_train:n_train + n_val]\n",
    "    y_val = y[n_train:n_train + n_val]\n",
    "\n",
    "    X_test = X[n_train + n_val:]\n",
    "    y_test = y[n_train + n_val:]\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b1bd73",
   "metadata": {},
   "source": [
    "# Kmeans 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51970abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d32203c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_plus_plus_init(X, k, seed=0):\n",
    "    np.random.seed(seed)\n",
    "    n_samples, _ = X.shape\n",
    "    centroids = np.zeros((k, X.shape[1]))\n",
    "    centroids[0] = X[np.random.choice(n_samples)]\n",
    "    closest = np.full(n_samples, np.inf)\n",
    "\n",
    "    for id in range(1, k):\n",
    "        dist_centroid = np.linalg.norm(X - centroids[id - 1], axis=1) ** 2\n",
    "        closest = np.minimum(closest, dist_centroid)\n",
    "        probs = closest / closest.sum()\n",
    "        cumu_probs = np.cumsum(probs)\n",
    "        r = np.random.rand()\n",
    "        next_idx = np.searchsorted(cumu_probs, r)\n",
    "        centroids[id] = X[next_idx]\n",
    "\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "767b6db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_clusters(X, centroids):\n",
    "    distances = np.linalg.norm(X[:, None] - centroids[None, :], axis=2)\n",
    "    return np.argmin(distances, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14f43bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_centroids(X, labels, k):\n",
    "    n = X.shape[1]\n",
    "    centroids = np.zeros((k, n))\n",
    "    for i in range(n):\n",
    "        cluster_points = X[labels == i]\n",
    "        if len(cluster_points) > 0:\n",
    "            centroids[i] = cluster_points.mean(axis=0)\n",
    "        else:\n",
    "            centroids[i] = X[np.random.choice(len(X))]\n",
    "\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3edd520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_wcss(X, labels, centroids):\n",
    "    total = 0.0\n",
    "    for k in range(len(centroids)):\n",
    "        cluster_points = X[labels == k]\n",
    "        dists = np.linalg.norm(cluster_points - centroids[k], axis=1) ** 2\n",
    "        total += dists.sum()\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8a125af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_j(X, labels, centroids):\n",
    "    wcss = compute_wcss(X, labels, centroids)\n",
    "    return wcss / X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e40a053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(X, k, epochs, seed=0):\n",
    "    centroids = kmeans_plus_plus_init(X, k, seed)\n",
    "    for i in range(epochs):\n",
    "        labels = assign_clusters(X, centroids)\n",
    "        new_centroids = update_centroids(X, labels, k)\n",
    "        if np.allclose(new_centroids, centroids):\n",
    "            break\n",
    "        centroids = new_centroids\n",
    "    labels = assign_clusters(X, centroids)\n",
    "    return centroids, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e41067a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kneedle_elbow(kmax, wcss_list):\n",
    "    x1, y1 = 1, wcss_list[0]\n",
    "    x2, y2 = kmax, wcss_list[-1]\n",
    "\n",
    "    max_dist = -1\n",
    "    elbow = 1\n",
    "\n",
    "    for k in range(1, kmax + 1):\n",
    "        x0 = k\n",
    "        y0 = wcss_list[k - 1]\n",
    "        numerator = abs((x2 - x1) * (y1 - y0) - (x1 - x0)*(y2 - y1))\n",
    "        denominator = np.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) \n",
    "        dist = numerator / denominator\n",
    "        if dist > max_dist:\n",
    "            max_dist = dist\n",
    "            eblow = k\n",
    "    return elbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4993a30e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
